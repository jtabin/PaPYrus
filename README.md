# PaPYrus
This is the first version of a program designed to perform Optical Character Recognition (OCR) on ancient Egyptian hieratic using an Image Deformation Model (IDM). This code allows the identification of individual unknown hieratic symbols, as well as facilitates large-scale comparisons of signs from across the textual corpus. For more information about this project, one is encouraged to read Julius Tabin's University of Chicago NELC undergraduate thesis: "From Papyrus to Pixels: Optical Character Recognition Applied to Ancient Egyptian Hieratic". A copy is provided in this repository. For people who wish to use the program to identify hieratic signs, but have no experience with Python, I suggest taking a look at the tutorial for image identification provided here:

https://docs.google.com/document/d/14aOFnfxtS4wxy1O6dD6IJatPK8bIaFQb5bMPWpL1uIM/edit?usp=sharing

If someone is interested in using the rest of the code before I am able to update it, feel free to. However, be aware that the code may be messy in places, have redundant elements, or be unintelligible to anyone but myself. Until the update, I am happy to answer any questions one might have; just email jtabin1@gmail.com.

### This program and data set are being offered for free and they always will be free. If someone is interested in using this program, I ask that the work you do with it also be made open-source and free. At the very least, please release any additions made to the data set. The more people that contribute to the data set and refine the analyses used here, the more the collective knowledge will expand and everyone will benefit. 

A brief description of each of the files included in this repository will follow. The files of code are presented in order of when they would be used (apart from "Identify One Image.ipynb", which is the code file for beginners). In the future, these will certainly be made easier to use.

- "Code":
  - "Identify One Image.ipynb": This code is a very simplified version of the program, purely for use in identifying individual hiratic signs. This is best for someone who does not know Python or wants a quick an easy version of the program. See the tutorial linked above for instructions on how to use it.    
  - "Data Set Prep.ipynb": This Jupyter Notebook file contains code to determine and save data set metrics (i.e. the sign values, aspect ratio, and resized pixel values of each sign in the data set) as .csv files. To use this, the input needs to be the data set ("Dataset Whole"). 
  - "Image Identification.ipynb": This uses IDM to identify signs and calculate their similarity to data set signs. The inputs here are the data set  with metrics ("Dataset Whole", "datasetstats.csv", and "pxls_XX.csv") and the signs to be identified (the unknown signs must be black and white). This can be an individual example of a sign, many individual signs, or even all of one sign. The output is two .csv files of all of the data set signs ranked. The top 10 candidate signs are displayed for each image input. 
  - "Multisign Analyses.ipynb": This code allows the creation of UMAP graphs. It takes the above two .csv files from the image identification step and outputs four UMAP graphs for each set of results files, colored by genre, provenance, facsmile maker, and text. Note: this will only produce meaningful results if the results files are of single signs where every sign is from the data set. If some signs aren't from the data set or are tagged incorrectly, then the result will be severely impacted.  
- "Data Set and Metrics":
  - "Dataset By Sign": This is every data set image, categorized in folders by their sign.
  - "Dataset Categorized": This is every data set image, categorized in folders by their provenance, text, and facsimile maker (i.e. where the tags originate from).
  - "Dataset Whole": This is every data set image in one folder. This is what is used for the analyses.
  - "Precalculated Data Set Stats": This is a collection of .csv files outputted by the "Data Set Prep.ipynb" code. This includes 3 sets of pixel values for every sign in the data set at 16, 20, and 25 pixels. It includes "datasetstats.csv" which are the aspect ratios and sign names for every sign in the data set. It also includes two files starting with "A1cut", which are the stats for the A1 tail cutting test done for the afformentioned undergraduate thesis. The files are ready to be used for "Image Identification.ipynb" and "Identify One Image.ipynb".
  -  "Precalculated OCR Results": This is a collection of .csv files outputted by the "Image Identification.ipynb" code. The files are mostly the product of all of one sign from the data set being used and they are labeled with the name of the sign. Some, such as "randsamp_fullresults.csv", come from other analyses outlined in the aformentioned undergraduate thesis (that file, for instance, is a random sample from the data set). The files are ready to be used for "Multisign Analyses.ipynb".

#### I hope this work is useful to the field and anyone who might need it. Please do not hesitate to contact me with questions!
